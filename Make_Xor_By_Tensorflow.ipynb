{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e27d8fa",
   "metadata": {},
   "source": [
    "# TensorflowでXorを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59ff07",
   "metadata": {},
   "source": [
    "訓練データと正解ラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53450c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#訓練データと正解ラベル\n",
    "train = np.array([[0,0],\n",
    "                              [0,1],\n",
    "                              [1,0],\n",
    "                              [1,1]])\n",
    "label = np.array([[0],\n",
    "                              [1],\n",
    "                              [1],\n",
    "                              [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70c549",
   "metadata": {},
   "source": [
    "## 1：モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1e097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの定義\n",
    "import tensorflow as tf\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    #多重パーセプトロン\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        # input_dim: 入力する1データあたりの値の形状\n",
    "        # hidden_dim(int): 隠れ層のニューロン数\n",
    "        # output_dim(int): 出力層のニューロン数\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        #l1: 隠れ層\n",
    "        self.l1 = tf.keras.layers.Dense(\n",
    "            units=hidden_dim,   # ニューロンのサイズ\n",
    "            input_dim=input_dim, # 入力データの形状\n",
    "            activation=\"sigmoid\")  # 活性化関数はシグモイド\n",
    "        #l2: 出力層\n",
    "        self.l2 = tf.keras.layers.Dense(\n",
    "            units=output_dim,# ニューロンのサイズ\n",
    "            activation=\"sigmoid\") # 活性化関数はシグモイド\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, x, training=None):\n",
    "        # x(ndarray(float32)): 訓練データまたは検証データ\n",
    "        # training(bool): 訓練True、検証False\n",
    "        # Returns(foalt32): 出力層からの出力値\n",
    "        h = self.l1(x) # 隠れ層の出力\n",
    "        y = self.l2(h) #出力層の出力\n",
    "        return y\n",
    "\n",
    "# 入力層2ニューロン、隠れ層2ニューロン、出力層1ニューロンのモデルを生成\n",
    "model = MLP(2, 2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b829d",
   "metadata": {},
   "source": [
    "## 2：損失関数とオプティマイザーの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c8bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#バイナリ用のクロスエントロピー誤差のオブジェクトを生成\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "#勾配降下アルゴリズムを使用するオプティマイザーを生成\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0bb41",
   "metadata": {},
   "source": [
    "## 4:バックプロバゲーション(逆誤差伝播法）を実行する関数の定義\n",
    "\n",
    "### 勾配降下アルゴリズムによるパラメーターの更新処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e94e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x,t):\n",
    "    # x(ndarray(float32)): 訓練データ\n",
    "    # t(ndarray(float32)): 正解ラベル\n",
    "    #　Returns：　MLPの出力と正解ラベルのクロスエントロピー誤差\n",
    "    \n",
    "    # 自動微分による勾配計算のための操作を記録するブロック\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x) #モデルに入力して順伝播の出力値を取得\n",
    "        pred_loss = loss_fn(t,predictions) # 出力値と正解ラベルの誤差を取得\n",
    "    \n",
    "    # tapeに記録された操作を使用して誤差の勾配を計算\n",
    "    gradients = tape.gradient(\n",
    "          pred_loss, # 現在の誤差\n",
    "          model.trainable_variables) # 更新可能なバイアス、重みのリストを取得\n",
    "    \n",
    "    # 勾配降下法の更新式を適用してバイアス、重みを更新\n",
    "    optimizer.apply_gradients(\n",
    "    zip(gradients, # 取得済みの勾配\n",
    "           model.trainable_variables)) # 更新可能なバイアス、重みのリスト\n",
    "    \n",
    "    return pred_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e86f44",
   "metadata": {},
   "source": [
    "## 5：モデルを定義して学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5f5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1000) loss: 0.1248\n",
      "epoch(2000) loss: 0.0183\n",
      "epoch(3000) loss: 0.0095\n",
      "epoch(4000) loss: 0.0064\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#　エポック数\n",
    "epochs = 4000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1エポックごとの損失を保持する変数\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # データをモデルに入力し、バイアス、重みを更新して誤差を取得\n",
    "    loss = train_step(train, label)\n",
    "    epoch_loss += loss.numpy()\n",
    "    \n",
    "    # 1000エポックごとに結果を出力\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(\"epoch({}) loss: {:.4f}\".format(epoch+1,epoch_loss))\n",
    "        \n",
    "# モデルの構造を出力\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d3143",
   "metadata": {},
   "source": [
    "## 6:学習結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dbbe6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00530535]\n",
      " [0.9930601 ]\n",
      " [0.99307287]\n",
      " [0.00615308]], shape=(4, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]], shape=(4, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(model(train))\n",
    "print(tf.cast(((model(train)) >= 0.5), tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db562be",
   "metadata": {},
   "source": [
    "## この結果から、Xorが実現できていることが分かる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32051465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
